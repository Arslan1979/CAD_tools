function [res]=roc_analysis(data,labels,niter,opt)

% ROC ANALYSIS FUNCTION
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Performs roc analysis and reports X, and Y of the ROC curve. Also AUC,
% optimal operation point, prevalence of the dataset and confidence
% intervals (alpha=0.05 or 95% confidence). The ROC curve is obtained iteratively,
% by repetition of clasification, based on the perfcurve function. The
% results can be obtained by bootstraping the scores of the test set or repeated cross validations.
% 
% Inputs:
%
%  data - (double) Training and test data
%  labels - (logical) labels of the data. 'false' is the negative class.
%  niter - (double) If niter is type double, cross validation is used. Number of iterations of the process for cross validation.
%          (string) If niter is type string, bootstrap is used. Number of
%          bootstraping iterations.
% 
%  opts - (string) Classifier used. Can be:
%                  'bayes' : The posteriori probabilities are tresholded for calculate the ROC
%                  'svm' :   The distance to the maximal hiperplane are tresholded
%                  'nearestmean': The distance to the class mean are tresholded, or
%                  'knn': The number of nearest neighbor are tresholded
%                  (maimum nearest neighbor = 8)
%
% Examples:
%  
%  >>[res]=roc_analysis(data,labels,30,'svm') 
%  A ROC curve is generated by the scores of svm classification. Test and
%  training data are generated from the data, taking 2/3 for training and
%  1/3 for test. Test and training data are selected randomly with
%  repetition in each of the 30 iterations. res.x and res.y contain the
%  1-specificity and sensitivity results, with the pointwise confidence
%  interval for each value, from vertical averaging (see perfcurve)
%
% >>[res]=roc_analysis(data,labels,'1000','bayes')
%  A ROC curve is generated by the a posteriori probabilities of bayes classification. Test and
%  training data are generated from the data, taking 2/3 for training and
%  1/3 for test. 1000 replicas of the scores obtained from the test are
%  generated with bootstrap and then averaged to obtain res.x and res.y
%  values together with the confidence intervals (see perfcurve)
%
%  10-1-2012 -------     Ignacio Alvarez Illan


labels=labels>0;
okopts={'bayes','svm','nearestmean','knn'};
type = find(strncmpi(opt, okopts,numel(opt)));
disp(' Calculating ROC curve ')
if ischar(niter)
    nit=str2double(niter);
    [output,testset]=rocdata(data,labels,type);
    crossscore=output;
    crosslabels=labels(testset);
    prevalence=sum(labels(testset))/numel(labels(testset));
    [x,y,t,auc,optpoint]=perfcurve(crosslabels, crossscore,'false','nboot',nit);
else
for k=1:niter
    disp(['Iteration number ' num2str(k)])
    [output,testset]=rocdata(data,labels,type);
    crossscore{k}=output;
    crosslabels{k}=labels(testset);
    prevalence{k}=sum(labels(testset))/numel(labels(testset));
    disp(['..completed!'])
end
[x,y,t,auc,optpoint]=perfcurve(crosslabels, crossscore,'false');
end
distt=([x(:,1) y(:,1)]-repmat(optpoint,size(x(:,1),1),1)).^2;
[a,b]=min(distt);
figure
plot(x,y)
xlim([0 1])
ylim([0 1])
xlabel('False positive rate'); ylabel('True positive rate')
title('ROC curve')
res.x=x;
res.y=y;
res.crossscore=crossscore;
res.crosslabels=crosslabels;
res.treshold=t;
res.areaundercurve=auc;
res.optimalpoint=[x(b(1),:); y(b(1),:)];
res.prevalence=prevalence;
end

function [output,test]=rocdata(data,labels,type)

P=size(data,1);
kernels= {'linear' };%  'rbf' 'quadratic'

% proportion in which training and test sets are divided
hsize=0.65;

[train,test] = crossvalind('HoldOut',P,hsize);
ptest=find(test);

if type==2
    nk=1;
    tt_labels=labels(train);
    tdata=data(train,:);
    svmStruct = svmtrain(tdata,tt_labels,'Kernel_Function',char(kernels(nk)));
    % Calculate the scores using the SVM
    for p=1:sum(test)
        sample=data(ptest(p),:); fprintf .
        if ~isempty(svmStruct.ScaleData)
            for c = 1:size(sample, 2)
                sample(:,c) = svmStruct.ScaleData.scaleFactor(c)*(sample(:,c) +  svmStruct.ScaleData.shift(c));
            end
        end
        output(p)=svmStruct.KernelFunction(svmStruct.SupportVectors,sample)'*svmStruct.Alpha+svmStruct.Bias;
    end
    
elseif type==1
    
    tr_data=data(train,:);
    tt_data=data(test,:); fprintf .
    nb = NaiveBayes.fit(tr_data, labels(train));
    [post] = posterior(nb, tt_data);
    output=post(:,1);
    
elseif type==3
    feat_norm=data(and(train',labels==0),:);
    feat_alz=data(and(train',labels>0),:);
    for p=1:sum(test)
        test_data=data(ptest(p),:);fprintf('.')
        output(p) = nm_classifier(feat_norm,feat_alz,test_data);
    end


elseif type==4
    kfol=8;
    tr_data=data(train,:);
    tt_data=data(test,:); fprintf .  
    [classes,counts] = knndistance(tt_data,tr_data,labels(train),kfol);
    output=counts(:,1);
end
end
